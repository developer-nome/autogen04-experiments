import asyncio
import os
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination
from autogen_core.models import ModelFamily, ModelInfo
from autogen_core import CancellationToken
from autogen_agentchat.ui import Console
from dotenv import load_dotenv

load_dotenv()

async def main() -> None:
    # Setup server params for local filesystem access
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # samples_dir = os.path.join(current_dir, "sample_files")
    samples_dir = "/Users/billhorn/code/python/autogen004/sample_files"

    # fetch_mcp_server = StdioServerParams(command="npx", args=["-y", "@modelcontextprotocol/server-filesystem@2025.3.28", "/Users/billhorn/code/python/autogen004/sample_files"])
    fetch_mcp_server = StdioServerParams(
        command="docker", args=[
            "run",
            "-i",
            "--rm",
            "--mount", f"type=bind,source={samples_dir},target=/samples_files",
            "mcp/filesystem",
            "/samples_files"
        ]
    )
    tools = await mcp_server_tools(fetch_mcp_server)

    # Create an agent that can use the fetch tool.
    model_client = OpenAIChatCompletionClient(
        # base_url='http://127.0.0.1:11434/v1', # omit for OpenAI calls
        # NOTE 4.1 nano did not work with the MCP server-filesystem tool
        # gpt-4.1-2025-04-14     = $2.00 / $ 8.00
        # gpt-5-2025-08-07       = $1.25 / $10.00
        # gpt-5-mini-2025-08-07  = $0.25 / $ 2.00
        model='gpt-4.1-2025-04-14',
        api_key=os.getenv("OPEN_AI_API_KEY"),
        model_info={
            "vision": False,
            "function_calling": True,
            "json_output": True,
            "family": ModelFamily.GPT_4O,
        }
    )
    agent = AssistantAgent(name="fetcher", model_client=model_client, tools=tools, reflect_on_tool_use=True)  # type: ignore 

    termination = MaxMessageTermination(
        max_messages=5) | TextMentionTermination("TERMINATE")

    team = RoundRobinGroupChat([agent], termination_condition=termination)
    #  team.dump_component().model_dump()
    # Using the MCP server-filesystem, Look in the sample_files directory and tell me what my favorite city is for pizza.
    await Console(team.run_stream(task="Add 5 random hat names to the favorite_hats.txt file", cancellation_token=CancellationToken()))
    
if __name__ == "__main__":
    asyncio.run(main())
